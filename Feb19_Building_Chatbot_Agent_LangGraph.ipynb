{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Building a Chatbot Agent in LangGraph\n",
    "In this tutorial, we will build a support chatbot using LangGraph. We will implement this chatbot via a graph workflow using nodes and edges.\n",
    "\n",
    "The chatbot will:\n",
    "\n",
    "Answer common questions by searching the web.\n",
    "Use custom tools to enhance its capabilities.\n",
    "Maintain conversation state across calls.\n",
    "This tutorial builds the foundation for more complex workflows and design patterns later in the course.\n",
    "\n",
    "Imports\n",
    "We start by importing the necessary libraries:"
   ],
   "id": "5df97055e2f1a9c4"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-19T20:35:42.806428Z",
     "start_time": "2026-02-19T20:35:42.800866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"ollama\"\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"http://localhost:11434/v1\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Defining the Model\n",
    "Initialize the language model:"
   ],
   "id": "d5c38a5ff63bfd83"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:37:05.683075Z",
     "start_time": "2026-02-19T20:37:05.523678Z"
    }
   },
   "cell_type": "code",
   "source": "llm = ChatOpenAI(model=\"gpt-oss:120b-cloud\", temperature=0)",
   "id": "df9211450a32bd2f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Defining the Tools\n",
    "We will define two tools:\n",
    "\n",
    "Tavily Search Tool: To fetch relevant information from the web.\n",
    "Current Date and Time Tool: Helps the chatbot respond to time-based queries."
   ],
   "id": "94fb248157d48566"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:35:39.312922Z",
     "start_time": "2026-02-19T20:35:39.299751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tavily Search Tool\n",
    "ddg_search = DuckDuckGoSearchResults(max_results=2)\n",
    "\n",
    "@tool\n",
    "def get_current_date() -> str:\n",
    "    \"\"\"Get today's date in YYYY-MM-DD format.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d\")"
   ],
   "id": "c6674d5140157325",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:36:32.295113Z",
     "start_time": "2026-02-19T20:36:32.292915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# list of tools for the agent\n",
    "tools = [ddg_search, get_current_date]"
   ],
   "id": "98289d383f1a3e0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:37:08.676041Z",
     "start_time": "2026-02-19T20:37:08.668231Z"
    }
   },
   "cell_type": "code",
   "source": "llm_with_tools = llm.bind_tools(tools)",
   "id": "a5b2bcf6eb45d9ab",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:37:30.954646Z",
     "start_time": "2026-02-19T20:37:30.949573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ],
   "id": "1855c3e653124e53",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:37:58.322386Z",
     "start_time": "2026-02-19T20:37:58.318031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ],
   "id": "2c132e512a5917d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10e75d7f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:38:19.872723Z",
     "start_time": "2026-02-19T20:38:19.869556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ],
   "id": "df2d15fa20724336",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10e75d7f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:38:44.295505Z",
     "start_time": "2026-02-19T20:38:44.292230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Conditional edge to decide whether to use tools, this is a prebuilt conditional edge\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "\n",
    "# If tools are used, return to the chatbot to process the tool output\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# Set the entry point of the graph\n",
    "graph_builder.set_entry_point(\"chatbot\")"
   ],
   "id": "a9b88591a6d3b701",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10e75d7f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:39:00.795041Z",
     "start_time": "2026-02-19T20:39:00.788125Z"
    }
   },
   "cell_type": "code",
   "source": "graph = graph_builder.compile()\n",
   "id": "218636d1dbdecfa",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:39:16.336710Z",
     "start_time": "2026-02-19T20:39:16.122741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "# Visualize the chatbot's workflow\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass  # Visualization requires additional dependencies"
   ],
   "id": "305e3d2ef6231b2f",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:39:40.964919Z",
     "start_time": "2026-02-19T20:39:40.961721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def render_markdown(md_string):\n",
    "    display(Markdown(md_string))\n",
    "\n",
    "def process_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "    return message\n",
    "\n",
    "def process_query(query, config=None):\n",
    "    inputs = {\"messages\": [(\"user\", query)]}\n",
    "    message = process_stream(graph.stream(inputs, config, stream_mode=\"values\"))\n",
    "    render_markdown(f\"## Answer:\\n{message.content}\")"
   ],
   "id": "5833f14c253f3175",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:40:00.956402Z",
     "start_time": "2026-02-19T20:39:56.931866Z"
    }
   },
   "cell_type": "code",
   "source": "process_query(\"Hello! What can you do?\")\n",
   "id": "545af6c1c626bc21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Hello! What can you do?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hey there! I‚Äôm ChatGPT, a versatile AI assistant that can help you with a wide range of tasks, such as:\n",
      "\n",
      "- **Answering questions** ‚Äì from everyday facts to deeper explanations in science, history, tech, art, and more.  \n",
      "- **Research & up‚Äëto‚Äëdate info** ‚Äì I can run a quick DuckDuckGo search for the latest news, recent studies, product specs, etc.  \n",
      "- **Writing & editing** ‚Äì drafts, essays, emails, stories, poems, resumes, cover letters, reports, and even social‚Äëmedia posts.  \n",
      "- **Programming help** ‚Äì explain concepts, debug code, write snippets in many languages, suggest algorithms, or walk you through a project.  \n",
      "- **Learning & tutoring** ‚Äì break down complex topics, create practice problems, generate flashcards, or design study plans.  \n",
      "- **Creative brainstorming** ‚Äì ideas for businesses, marketing campaigns, games, gifts, party themes, travel itineraries, recipes, and more.  \n",
      "- **Data & math** ‚Äì perform calculations, generate tables or simple visualizations, explain statistics, solve equations, etc.  \n",
      "- **Productivity support** ‚Äì make to‚Äëdo lists, outline meeting agendas, draft schedules, set reminders (via external tools), and help you stay organized.  \n",
      "- **Conversational companion** ‚Äì chat about books, movies, philosophy, hobbies, or just have a friendly conversation.\n",
      "\n",
      "I also have a couple of built‚Äëin tools:\n",
      "\n",
      "- **`duckduckgo_results_json`** ‚Äì lets me fetch live search results for the latest information.  \n",
      "- **`get_current_date`** ‚Äì gives me today‚Äôs date in YYYY‚ÄëMM‚ÄëDD format.\n",
      "\n",
      "Just let me know what you need, and I‚Äôll dive in! üöÄ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Answer:\nHey there! I‚Äôm ChatGPT, a versatile AI assistant that can help you with a wide range of tasks, such as:\n\n- **Answering questions** ‚Äì from everyday facts to deeper explanations in science, history, tech, art, and more.  \n- **Research & up‚Äëto‚Äëdate info** ‚Äì I can run a quick DuckDuckGo search for the latest news, recent studies, product specs, etc.  \n- **Writing & editing** ‚Äì drafts, essays, emails, stories, poems, resumes, cover letters, reports, and even social‚Äëmedia posts.  \n- **Programming help** ‚Äì explain concepts, debug code, write snippets in many languages, suggest algorithms, or walk you through a project.  \n- **Learning & tutoring** ‚Äì break down complex topics, create practice problems, generate flashcards, or design study plans.  \n- **Creative brainstorming** ‚Äì ideas for businesses, marketing campaigns, games, gifts, party themes, travel itineraries, recipes, and more.  \n- **Data & math** ‚Äì perform calculations, generate tables or simple visualizations, explain statistics, solve equations, etc.  \n- **Productivity support** ‚Äì make to‚Äëdo lists, outline meeting agendas, draft schedules, set reminders (via external tools), and help you stay organized.  \n- **Conversational companion** ‚Äì chat about books, movies, philosophy, hobbies, or just have a friendly conversation.\n\nI also have a couple of built‚Äëin tools:\n\n- **`duckduckgo_results_json`** ‚Äì lets me fetch live search results for the latest information.  \n- **`get_current_date`** ‚Äì gives me today‚Äôs date in YYYY‚ÄëMM‚ÄëDD format.\n\nJust let me know what you need, and I‚Äôll dive in! üöÄ"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:40:52.599760Z",
     "start_time": "2026-02-19T20:40:51.059670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Query that requires current date\n",
    "process_query(\"What is the current date?\")"
   ],
   "id": "efdbc2fd39189292",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is the current date?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  get_current_date (call_sdes9j3r)\n",
      " Call ID: call_sdes9j3r\n",
      "  Args:\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: get_current_date\n",
      "\n",
      "2026-02-19\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Today's date is **2026‚Äë02‚Äë19**.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Answer:\nToday's date is **2026‚Äë02‚Äë19**."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:41:37.701861Z",
     "start_time": "2026-02-19T20:41:25.611234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Query that triggers the Tavily search tool\n",
    "process_query(\"What is LangGraph?\")"
   ],
   "id": "945fe150c2cf3438",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is LangGraph?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "**LangGraph ‚Äì a quick‚Äëlook overview**\n",
      "\n",
      "| Aspect | What it is | Why it matters |\n",
      "|--------|------------|----------------|\n",
      "| **Type** | An open‚Äësource Python library (and now a first‚Äëclass component of the LangChain ecosystem) that lets you describe, build, and run **graph‚Äëstructured LLM workflows**. | Turns a linear chain of prompts into a full‚Äëfeatured, stateful, branching ‚Äúprogram‚Äù that can loop, make decisions, call tools, and maintain context. |\n",
      "| **Core idea** | Treat each step of an LLM‚Äëpowered application (prompt, tool call, function, retrieval, agent, etc.) as a **node** in a directed graph. Edges encode the flow of data (the *state*) from one node to the next. | Gives you a visual, modular, and debuggable way to compose complex multi‚Äëturn interactions‚Äîthink ‚Äúif‚Äëelse‚Äù, ‚Äúwhile‚Äù, ‚Äúfork‚Äëjoin‚Äù, or ‚Äúre‚Äëtry until success‚Äù patterns. |\n",
      "| **Key building blocks** | 1. **Node / Runnable** ‚Äì a callable that receives a **State** (a dict‚Äëlike object) and returns an updated State.  <br>2. **State** ‚Äì the shared context that travels along edges (messages, retrieved docs, tool results, flags, counters, etc.). <br>3. **Graph** ‚Äì a collection of nodes + edges, usually defined with a simple DSL (`graph.add_edge(\"A\", \"B\")` or via a `graph.yaml`). <br>4. **Condition / Trigger** ‚Äì functions that decide which outgoing edge to follow based on the current state. <br>5. **Loop / Sub‚Äëgraph** ‚Äì you can nest graphs or create loops that re‚Äëenter a node until a predicate is satisfied. | These abstractions let you write ‚ÄúLLM programs‚Äù that look more like ordinary Python code (or a visual flowchart) rather than a long chain of `chain.run()` calls. |\n",
      "| **How it fits with LangChain** | LangGraph re‚Äëuses LangChain‚Äôs `Runnable` interface, `PromptTemplate`, `ChatOpenAI` (or any other LLM), `retrievers`, `tools`, and callbacks. It‚Äôs essentially the **graph‚Äëoriented sibling** of LangChain‚Äôs `Chain` and `Agent` abstractions. | If you already use LangChain, you can drop in a `Graph` with almost no friction. If you need more expressive control flow than a linear chain, LangGraph is the natural next step. |\n",
      "| **Typical use‚Äëcases** | ‚Ä¢ Multi‚Äëturn agents that need to *think*, *search*, *act*, and *reflect* (e.g., research assistants). <br>‚Ä¢ Decision‚Äëmaking pipelines (e.g., ‚Äúclassify ‚Üí route to tool A/B ‚Üí post‚Äëprocess‚Äù). <br>‚Ä¢ Looped refinement (e.g., ‚Äúgenerate answer ‚Üí self‚Äëcritique ‚Üí revise until confidence >‚ÄØ0.9‚Äù). <br>‚Ä¢ Orchestrating several tools: retrieval ‚Üí summarization ‚Üí Q&A ‚Üí database write. | Anything that involves **stateful, conditional, or iterative** interactions with LLMs and external resources. |\n",
      "| **Visualization** | Built‚Äëin support for **GraphViz / Mermaid** rendering. You can call `graph.draw()` (or `graph.visualize()`) to get a PNG/SVG or an interactive HTML diagram that shows node names, edge conditions, and current state values. | Makes debugging, documentation, and stakeholder communication much easier. |\n",
      "| **Installation** | ```bash\\npip install langgraph\\n``` | Works with Python‚ÄØ3.9+. It pulls in LangChain as a dependency, so you already have the LLM wrappers. |\n",
      "| **Simple example** | ```python\\nfrom langgraph.graph import StateGraph, START, END\\nfrom langchain.chat_models import ChatOpenAI\\nfrom langchain.prompts import PromptTemplate\\n\\n# 1Ô∏è‚É£ Define nodes\\n\\ndef generate(state):\\n    llm = ChatOpenAI()\\n    prompt = PromptTemplate.from_template(\\\"Answer the question: {question}\\\")\\n    answer = llm.invoke(prompt.format(question=state[\\\"question\\\"]))\\n    state[\\\"answer\\\"] = answer.content\\n    return state\\n\\ndef check_quality(state):\\n    # Very naive quality check ‚Äì e.g., length > 20 chars\\n    state[\\\"good\\\"] = len(state[\\\"answer\\\"]) > 20\\n    return state\\n\\n# 2Ô∏è‚É£ Build the graph\\n\\ng = StateGraph(START)\\n\\ng.add_node(\\\"generate\\\", generate)\\n\\ng.add_node(\\\"check\\\", check_quality)\\n\\ng.add_edge(START, \\\"generate\\\")\\n\\ng.add_conditional_edges(\\n    \\\"generate\\\",\\n    lambda s: \\\"check\\\" if s[\\\"good\\\"] else END,  # if answer good ‚Üí check, else finish early\\n)\\n\\ng.add_edge(\\\"check\\\", END)\\n\\n# 3Ô∏è‚É£ Run it\\nworkflow = g.compile()\\nresult = workflow.invoke({\\\"question\\\": \\\"What is quantum tunnelling?\\\"})\\nprint(result[\\\"answer\\\"])\\n```\\nThe graph runs *generate ‚Üí check ‚Üí END* (or skips to END if the condition fails). | Shows how a tiny graph replaces several separate chain objects and gives you an explicit control flow. |\n",
      "| **Advanced features** | ‚Ä¢ **Async support** ‚Äì nodes can be `async def` and the whole graph can be executed with `await`. <br>‚Ä¢ **Streaming** ‚Äì hook into LLM token streams via LangChain callbacks. <br>‚Ä¢ **Memory integration** ‚Äì you can attach a `Memory` object to the graph so that each run automatically sees previous states. <br>‚Ä¢ **Tool adapters** ‚Äì export a graph as a LangChain `Agent` so that external callers can treat it like a single tool. | Enables production‚Äëgrade pipelines (async APIs, partial responses, persistent memory). |\n",
      "| **Where to learn more** | ‚Ä¢ **Docs** ‚Äì https://langchain.com/langgraph <br>‚Ä¢ **GitHub repo** ‚Äì https://github.com/langchain-ai/langgraph (readme, examples, tutorial notebooks). <br>‚Ä¢ **Blog posts** ‚Äì ‚ÄúBuilding Loopy LLM Agents with LangGraph‚Äù (LangChain blog, Oct‚ÄØ2023). <br>‚Ä¢ **YouTube** ‚Äì ‚ÄúLangGraph Deep Dive‚Äù (LangChain channel). | Good starting points for hands‚Äëon experimentation. |\n",
      "| **Community & Ecosystem** | ‚Ä¢ Active Discord/Slack channel under the LangChain community. <br>‚Ä¢ A growing list of community‚Äëcontributed graph templates (e.g., ‚Äúresearch‚Äëassistant‚Äù, ‚Äúcode‚Äëreview‚Äëloop‚Äù). <br>‚Ä¢ Compatibility with LangServe, LangSmith observability, and LangFuse for monitoring. | You can reuse patterns or request help quickly. |\n",
      "\n",
      "---\n",
      "\n",
      "### TL;DR (one‚Äësentence definition)\n",
      "\n",
      "**LangGraph is a graph‚Äëbased orchestration framework for LLM applications that lets you define nodes (prompt/tool steps) and conditional/looping edges, enabling complex, stateful, and visualizable workflows built on top of LangChain.**\n",
      "\n",
      "If you‚Äôre already using LangChain and find yourself writing long, linear chains or custom ‚Äúif‚Äëelse‚Äù code around LLM calls, LangGraph gives you a clean, modular, and debuggable way to turn that logic into an explicit graph.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Answer:\n**LangGraph ‚Äì a quick‚Äëlook overview**\n\n| Aspect | What it is | Why it matters |\n|--------|------------|----------------|\n| **Type** | An open‚Äësource Python library (and now a first‚Äëclass component of the LangChain ecosystem) that lets you describe, build, and run **graph‚Äëstructured LLM workflows**. | Turns a linear chain of prompts into a full‚Äëfeatured, stateful, branching ‚Äúprogram‚Äù that can loop, make decisions, call tools, and maintain context. |\n| **Core idea** | Treat each step of an LLM‚Äëpowered application (prompt, tool call, function, retrieval, agent, etc.) as a **node** in a directed graph. Edges encode the flow of data (the *state*) from one node to the next. | Gives you a visual, modular, and debuggable way to compose complex multi‚Äëturn interactions‚Äîthink ‚Äúif‚Äëelse‚Äù, ‚Äúwhile‚Äù, ‚Äúfork‚Äëjoin‚Äù, or ‚Äúre‚Äëtry until success‚Äù patterns. |\n| **Key building blocks** | 1. **Node / Runnable** ‚Äì a callable that receives a **State** (a dict‚Äëlike object) and returns an updated State.  <br>2. **State** ‚Äì the shared context that travels along edges (messages, retrieved docs, tool results, flags, counters, etc.). <br>3. **Graph** ‚Äì a collection of nodes + edges, usually defined with a simple DSL (`graph.add_edge(\"A\", \"B\")` or via a `graph.yaml`). <br>4. **Condition / Trigger** ‚Äì functions that decide which outgoing edge to follow based on the current state. <br>5. **Loop / Sub‚Äëgraph** ‚Äì you can nest graphs or create loops that re‚Äëenter a node until a predicate is satisfied. | These abstractions let you write ‚ÄúLLM programs‚Äù that look more like ordinary Python code (or a visual flowchart) rather than a long chain of `chain.run()` calls. |\n| **How it fits with LangChain** | LangGraph re‚Äëuses LangChain‚Äôs `Runnable` interface, `PromptTemplate`, `ChatOpenAI` (or any other LLM), `retrievers`, `tools`, and callbacks. It‚Äôs essentially the **graph‚Äëoriented sibling** of LangChain‚Äôs `Chain` and `Agent` abstractions. | If you already use LangChain, you can drop in a `Graph` with almost no friction. If you need more expressive control flow than a linear chain, LangGraph is the natural next step. |\n| **Typical use‚Äëcases** | ‚Ä¢ Multi‚Äëturn agents that need to *think*, *search*, *act*, and *reflect* (e.g., research assistants). <br>‚Ä¢ Decision‚Äëmaking pipelines (e.g., ‚Äúclassify ‚Üí route to tool A/B ‚Üí post‚Äëprocess‚Äù). <br>‚Ä¢ Looped refinement (e.g., ‚Äúgenerate answer ‚Üí self‚Äëcritique ‚Üí revise until confidence >‚ÄØ0.9‚Äù). <br>‚Ä¢ Orchestrating several tools: retrieval ‚Üí summarization ‚Üí Q&A ‚Üí database write. | Anything that involves **stateful, conditional, or iterative** interactions with LLMs and external resources. |\n| **Visualization** | Built‚Äëin support for **GraphViz / Mermaid** rendering. You can call `graph.draw()` (or `graph.visualize()`) to get a PNG/SVG or an interactive HTML diagram that shows node names, edge conditions, and current state values. | Makes debugging, documentation, and stakeholder communication much easier. |\n| **Installation** | ```bash\\npip install langgraph\\n``` | Works with Python‚ÄØ3.9+. It pulls in LangChain as a dependency, so you already have the LLM wrappers. |\n| **Simple example** | ```python\\nfrom langgraph.graph import StateGraph, START, END\\nfrom langchain.chat_models import ChatOpenAI\\nfrom langchain.prompts import PromptTemplate\\n\\n# 1Ô∏è‚É£ Define nodes\\n\\ndef generate(state):\\n    llm = ChatOpenAI()\\n    prompt = PromptTemplate.from_template(\\\"Answer the question: {question}\\\")\\n    answer = llm.invoke(prompt.format(question=state[\\\"question\\\"]))\\n    state[\\\"answer\\\"] = answer.content\\n    return state\\n\\ndef check_quality(state):\\n    # Very naive quality check ‚Äì e.g., length > 20 chars\\n    state[\\\"good\\\"] = len(state[\\\"answer\\\"]) > 20\\n    return state\\n\\n# 2Ô∏è‚É£ Build the graph\\n\\ng = StateGraph(START)\\n\\ng.add_node(\\\"generate\\\", generate)\\n\\ng.add_node(\\\"check\\\", check_quality)\\n\\ng.add_edge(START, \\\"generate\\\")\\n\\ng.add_conditional_edges(\\n    \\\"generate\\\",\\n    lambda s: \\\"check\\\" if s[\\\"good\\\"] else END,  # if answer good ‚Üí check, else finish early\\n)\\n\\ng.add_edge(\\\"check\\\", END)\\n\\n# 3Ô∏è‚É£ Run it\\nworkflow = g.compile()\\nresult = workflow.invoke({\\\"question\\\": \\\"What is quantum tunnelling?\\\"})\\nprint(result[\\\"answer\\\"])\\n```\\nThe graph runs *generate ‚Üí check ‚Üí END* (or skips to END if the condition fails). | Shows how a tiny graph replaces several separate chain objects and gives you an explicit control flow. |\n| **Advanced features** | ‚Ä¢ **Async support** ‚Äì nodes can be `async def` and the whole graph can be executed with `await`. <br>‚Ä¢ **Streaming** ‚Äì hook into LLM token streams via LangChain callbacks. <br>‚Ä¢ **Memory integration** ‚Äì you can attach a `Memory` object to the graph so that each run automatically sees previous states. <br>‚Ä¢ **Tool adapters** ‚Äì export a graph as a LangChain `Agent` so that external callers can treat it like a single tool. | Enables production‚Äëgrade pipelines (async APIs, partial responses, persistent memory). |\n| **Where to learn more** | ‚Ä¢ **Docs** ‚Äì https://langchain.com/langgraph <br>‚Ä¢ **GitHub repo** ‚Äì https://github.com/langchain-ai/langgraph (readme, examples, tutorial notebooks). <br>‚Ä¢ **Blog posts** ‚Äì ‚ÄúBuilding Loopy LLM Agents with LangGraph‚Äù (LangChain blog, Oct‚ÄØ2023). <br>‚Ä¢ **YouTube** ‚Äì ‚ÄúLangGraph Deep Dive‚Äù (LangChain channel). | Good starting points for hands‚Äëon experimentation. |\n| **Community & Ecosystem** | ‚Ä¢ Active Discord/Slack channel under the LangChain community. <br>‚Ä¢ A growing list of community‚Äëcontributed graph templates (e.g., ‚Äúresearch‚Äëassistant‚Äù, ‚Äúcode‚Äëreview‚Äëloop‚Äù). <br>‚Ä¢ Compatibility with LangServe, LangSmith observability, and LangFuse for monitoring. | You can reuse patterns or request help quickly. |\n\n---\n\n### TL;DR (one‚Äësentence definition)\n\n**LangGraph is a graph‚Äëbased orchestration framework for LLM applications that lets you define nodes (prompt/tool steps) and conditional/looping edges, enabling complex, stateful, and visualizable workflows built on top of LangChain.**\n\nIf you‚Äôre already using LangChain and find yourself writing long, linear chains or custom ‚Äúif‚Äëelse‚Äù code around LLM calls, LangGraph gives you a clean, modular, and debuggable way to turn that logic into an explicit graph."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:42:35.975803Z",
     "start_time": "2026-02-19T20:42:31.542632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Time-based query about an event\n",
    "process_query(\"When is the next olympics?\")"
   ],
   "id": "9703326849575549",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "When is the next olympics?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  get_current_date (call_eca4n7pz)\n",
      " Call ID: call_eca4n7pz\n",
      "  Args:\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: get_current_date\n",
      "\n",
      "2026-02-19\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "The next edition of the Olympic Games is the **2026 Winter Olympics** in **Milan‚ÄëCortina d‚ÄôAmpezzo, Italy**.  \n",
      "- **Dates:** **6‚ÄØ‚Äì‚ÄØ22‚ÄØFebruary‚ÄØ2026** (the Games are already underway as of today).\n",
      "\n",
      "The following Olympic Games after that will be the **2028 Summer Olympics** in **Los Angeles, USA**.  \n",
      "- **Dates:** **21‚ÄØJuly‚ÄØ‚Äì‚ÄØ6‚ÄØAugust‚ÄØ2028**.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Answer:\nThe next edition of the Olympic Games is the **2026 Winter Olympics** in **Milan‚ÄëCortina d‚ÄôAmpezzo, Italy**.  \n- **Dates:** **6‚ÄØ‚Äì‚ÄØ22‚ÄØFebruary‚ÄØ2026** (the Games are already underway as of today).\n\nThe following Olympic Games after that will be the **2028 Summer Olympics** in **Los Angeles, USA**.  \n- **Dates:** **21‚ÄØJuly‚ÄØ‚Äì‚ÄØ6‚ÄØAugust‚ÄØ2028**."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:43:20.569526Z",
     "start_time": "2026-02-19T20:43:19.366561Z"
    }
   },
   "cell_type": "code",
   "source": "process_query(\"Hi. My name is bappi. Who are you?\")\n",
   "id": "856aa15c71cdbca2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Hi. My name is bappi. Who are you?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hello,‚ÄØBappi! üëã I'm ChatGPT, an AI language model created by‚ÄØOpenAI. I‚Äôm here to answer questions, brainstorm ideas, help with writing, explain concepts, or just have a friendly chat‚Äîwhatever you need. How can I help you today?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Answer:\nHello,‚ÄØBappi! üëã I'm ChatGPT, an AI language model created by‚ÄØOpenAI. I‚Äôm here to answer questions, brainstorm ideas, help with writing, explain concepts, or just have a friendly chat‚Äîwhatever you need. How can I help you today?"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:43:40.154743Z",
     "start_time": "2026-02-19T20:43:39.116931Z"
    }
   },
   "cell_type": "code",
   "source": "process_query(\"What is my name?\")\n",
   "id": "afebe75e0e0dd0d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is my name?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "I don‚Äôt actually have any information about your name. Could you let me know what you‚Äôd like me to call you?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Answer:\nI don‚Äôt actually have any information about your name. Could you let me know what you‚Äôd like me to call you?"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:44:08.835514Z",
     "start_time": "2026-02-19T20:44:08.831373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ],
   "id": "c5fefb1c635c8d27",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:44:40.821819Z",
     "start_time": "2026-02-19T20:44:40.818277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compile the graph with the checkpointer\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ],
   "id": "5f92a7841e6eca6b",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:45:04.519503Z",
     "start_time": "2026-02-19T20:45:03.500281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_user_1 = {\"thread_id\": \"user_1\"}\n",
    "process_query(\"Hi. My name is Sajal. Who are you?\", config=config_user_1)"
   ],
   "id": "645dc02c27863d91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Hi. My name is Sajal. Who are you?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hello Sajal! I‚Äôm ChatGPT, an AI language model created by OpenAI. I can help answer questions, brainstorm ideas, explain concepts, draft writing, troubleshoot problems, and much more. Feel free to let me know what you‚Äôd like to talk about or explore!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Answer:\nHello Sajal! I‚Äôm ChatGPT, an AI language model created by OpenAI. I can help answer questions, brainstorm ideas, explain concepts, draft writing, troubleshoot problems, and much more. Feel free to let me know what you‚Äôd like to talk about or explore!"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:45:23.348973Z",
     "start_time": "2026-02-19T20:45:22.525825Z"
    }
   },
   "cell_type": "code",
   "source": "process_query(\"What is my name?\", config=config_user_1)\n",
   "id": "ac905476a77fdd99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is my name?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "You told me your name is **Sajal**. Nice to meet you!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Answer:\nYou told me your name is **Sajal**. Nice to meet you!"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:45:50.049103Z",
     "start_time": "2026-02-19T20:45:49.134564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Checking if memory is shared across threads\n",
    "config_user_2 = {\"thread_id\": \"user_2\"}\n",
    "process_query(\"What is my name?\", config=config_user_2)"
   ],
   "id": "1fd365f322c6eb9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is my name?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "I‚Äôm sorry, but I don‚Äôt have any information about your name. If you‚Äôd like to share it, I‚Äôll be happy to address you by it!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Answer:\nI‚Äôm sorry, but I don‚Äôt have any information about your name. If you‚Äôd like to share it, I‚Äôll be happy to address you by it!"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
